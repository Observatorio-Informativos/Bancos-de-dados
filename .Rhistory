STQ
#STQReg precisa da matrix dos betas e dos valores de X1,X2,
alpha<-matrix(c(1,1,1,1)) #criando matriz de valores 1 para alpha
X<-cbind(alpha,X1,X2) #cbind consolida as matrizes alpha, X1, e X2 em uma unica matriz 4X3
X
B<-matrix(c(coefficients(regI))) #criando matriz de coeficientes, poderia alternativamente usar os valores dos coeficientes
B
SQReg<-t(B)%*%t(X)%*%Y-(n%*%mean(Y)^2) # parcela da variância explicada pela regressão
SQReg
#para SQres podemos usar a matrix dos erros (soma quadrada dos erros da regressão)
E<-matrix(c(residuals(regI))) # criando matrix dos erros
E
SQRes<-t(E)%*%E # parcela da variancia explicada pelos resídos
SQRes
#tabela ANOVA e interpre o teste F
#note que a tabela da pg 117 pode ser replicada com os resultados que ja temos.
#o R, no entanto tem um comando para computar estatísticas da ANOVA.
anova<-anova(regI) # comparando os dois modelos na tabela ANOVA
anova #
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # 182.25,
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regI) #a probabilidade de incorrer em erro ao rejeitar H0=B1=B2=0 é de 5.2%, logo se pode rejeitar H0.
#b) Pressupondo que a relação entre as variáveis seja dada por ln(Y)=alpha+B1ln(X1)+B2ln(X2)+e
#seria possível realizar a análise de variância, justifique.
#criar base d2 com logs
lnY<-log(Y)
lnX1<-log(X1)
lnX2<-log(X2)
d2<-data.frame(log(Y),log(X1),log(X2))
#renomeando variáveis
colnames(d2)[1]<-"lnY"
colnames(d2)[2]<-"lnX1"
colnames(d2)[3]<-"lnX2"
#Estimando o modelo como suporte
regII<-lm(lnY~lnX1+lnX2,data=d2)
summary(regII)
previsto<-predict(regII) #valores previstos
previsto
residuos<-residuals(regII) #residuos
residuos
#criando k e n
k<-2 #numero de parametros, ou betas (lembrar do alpha)
n<-4 #número de observações
#calculando STQ, SQReg e SQRes
STQ<-t(lnY)%*%lnY-n%*%mean(lnY)^2 ##ver eq (1) pag 115. Alternativamente poderia ter calculado (Yi-Ymedio)^2
STQ
#STQReg precisa da matrix dos betas e dos valores de X1,X2,
alpha<-matrix(c(1,1,1,1)) #criando matriz de valores 1 para alpha
X<-cbind(alpha,lnX1,lnX2) #cbind consolida as matrizes alpha, X1, e X2 em uma unica matriz 4X3
X
B<-matrix(c(coefficients(regII))) #criando matriz de coeficientes, poderia alternativamente usar os valores dos coeficientes
B
SQReg<-t(B)%*%t(X)%*%lnY-(n%*%mean(lnY)^2) # parcela da variância explicada pela regressão
SQReg
#para SQres podemos usar a matrix dos erros (soma quadrada dos erros da regressão)
E<-matrix(c(residuals(regII))) # criando matrix dos erros
E
SQRes<-t(E)%*%E # parcela da variancia explicada pelos resídos
SQRes
#tabela ANOVA e interpre o teste F
#note que a tabela da pg 117 pode ser replicada com os resultados que ja temos.
#o R, no entanto tem um comando para computar estatísticas da ANOVA.
anova<-anova(regII) # comparando os dois modelos na tabela ANOVA
anova #
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # -77385.45
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regII) #a probabilidade de incorrer em erro ao rejeitar H0=B1=B2=0 é de 5.2%, logo se pode rejeitar H0.
#1 - Sejam as informações sobre os gastos mensais com alimentação (Y, em 1000 reais),
#renda mensal (X, em 1000 reais) e a distancia ao supermercado mais próximo (X2, em Km) de quatro famílias. Pressupondo uma relaçao linear entre a variável Y e
#as variáveis independentes X1 e X2 pede-se:
rm(list=ls(all=TRUE))
#a) Estime e interprete os coeficientes do modelo de regressão linear múltipla para os gastos mensais com alimentação em função
#da renda mensal e distância do supermercado:
regI<-lm(Y~.,data=d1)
#a) Estime e interprete os coeficientes do modelo de regressão linear múltipla para os gastos mensais com alimentação em função
#da renda mensal e distância do supermercado:
regI<-lm(Y~.,data=d1)
d1<-data.frame(Y,X1,X2)
#a) Estime e interprete os coeficientes do modelo de regressão linear múltipla para os gastos mensais com alimentação em função
#da renda mensal e distância do supermercado:
regI<-lm(Y~.,data=d1)
#criando banco de dados
Y<-matrix(c(0.4,0.2,0.3,0.6)) #vetor do gasto em supermecados em mil reais
X1<-matrix(c(1,2,2,3))#vetor da renda em mil reais
X2<-matrix(c(2,3,3,2))#vetor da distancia
d1<-data.frame(Y,X1,X2)
#a) Estime e interprete os coeficientes do modelo de regressão linear múltipla para os gastos mensais com alimentação em função
#da renda mensal e distância do supermercado:
regI<-lm(Y~.,data=d1)
summary(regI)
#2 - Sejam as seguintes informações sobre o consumo de frando Y, renda disponível X1 e preço do
#do frnado X2 em quatro diferentes anos:
rm(list=ls(all=TRUE))
Y<-matrix(c(74,82,84,110)) # consumo de frango em kg/per capita
X1<-matrix(c(6,8,8,10)) # renda em 1000 $
X2<-matrix(c(0.8,1.2,1.2,1.0)) # preço do frando R$/Kg
d1<-data.frame(Y,X1,X2)
#a) estime e interprete os coeficientes da função de demanda, relacionando o consumo à renda
#e ao preço do frango:
regI<-lm(Y~.,data=d1)
summary(regI)
regII<-lm(log(Y)~log(X1)+log(X2), data=d1)
summary(regII)
#1 - Sejam as informações sobre os gastos mensais com alimentação (Y, em 1000 reais),
#renda mensal (X, em 1000 reais) e a distancia ao supermercado mais próximo (X2, em Km) de quatro famílias. Pressupondo uma relaçao linear entre a variável Y e
#as variáveis independentes X1 e X2 pede-se:
rm(list=ls(all=TRUE))
#criando banco de dados
Y<-matrix(c(0.4,0.2,0.3,0.6)) #vetor do gasto em supermecados em mil reais
X1<-matrix(c(1,2,2,3))#vetor da renda em mil reais
X2<-matrix(c(2,3,3,2))#vetor da distancia
d1<-data.frame(Y,X1,X2)
#Estimando o modelo como suporte
regI<-lm(Y~.,data=d1)
summary(regI)
previsto<-predict(regI) #valores previstos
previsto
residuos<-residuals(regI) #residuos
residuos
#a)calcule a STQ, SQReg e SQRes
STQ<-t(Y)%*%Y-n%*%mean(Y)^2 ##ver eq (1) pag 115. Alternativamente poderia ter calculaso (Yi-Ymedio)^2
#criando k e n
k<-2 #numero de parametros, ou betas (lembrar do alpha)
n<-4 #número de observações
#a)calcule a STQ, SQReg e SQRes
STQ<-t(Y)%*%Y-n%*%mean(Y)^2 ##ver eq (1) pag 115. Alternativamente poderia ter calculaso (Yi-Ymedio)^2
STQ
#STQReg precisa da matrix dos betas e dos valores de X1,X2,
alpha<-matrix(c(1,1,1,1)) #criando matriz de valores 1 para alpha
X<-cbind(alpha,X1,X2) #cbind consolida as matrizes alpha, X1, e X2 em uma unica matriz 4X3
X
summary(regI)
B<-matrix(c(coefficients(regI))) #criando matriz de coeficientes, poderia alternativamente usar os valores dos coeficientes
B
SQReg<-t(B)%*%t(X)%*%Y-(n%*%mean(Y)^2) # parcela da variância explicada pela regressão
SQReg
#para SQres podemos usar a matrix dos erros (soma quadrada dos erros da regressão)
E<-matrix(c(residuals(regI))) # criando matrix dos erros
E
SQRes<-t(E)%*%E # parcela da variancia explicada pelos resídos
SQRes
#b) calcule e interprete R2 e R2 ajustado
# a estatística do R2 (coficiente de determinação) representa o percentual da variancia total (STQ) que pode ser atribuida a SQREg
R2<-SQReg/STQ
R2 #94.285% da variancia total é explicada pela regressão, o restante é explicado pelos resíduos.
summary(regi)
summary(regI)
X
R2aj<-1-(SQRes/(n-(k+1)))/(STQ/(n-1))
R2aj #82.85 da variancia é explicada pelo coeficiente de determinação ajustado.
#c)construa a tabela ANOVA e interpre o teste F
#note que a tabela da pg 117 pode ser replicada com os resultados que ja temos.
#o R, no entanto tem um comando para computar estatísticas da ANOVA.
anova<-anova(regI) # comparando os dois modelos na tabela ANOVA
anova #
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # 8.25
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regI) #a probabilidade de incorrer em erro ao rejeitar H0=B1=B2=0 é de 23.9%, logo não se pode rejeitar H0.
lnY<-log(Y)
lnX1<-log(X1)
lnX2<-log(X2)
d2<-data.frame(log(Y),log(X1),log(X2))
#renomeando variáveis
colnames(d2)[1]<-"lnY"
colnames(d2)[2]<-"lnX1"
colnames(d2)[3]<-"lnX2"
#Estimando o modelo como suporte
regII<-lm(lnY~lnX1+lnX2,data=d2)
summary(regII)
previsto<-predict(regII) #valores previstos
previsto
residuos<-residuals(regII) #residuos
residuos
#criando k e n
k<-2 #numero de parametros, ou betas (lembrar do alpha)
n<-4 #número de observações
#calculando STQ, SQReg e SQRes
STQ<-t(lnY)%*%lnY-n%*%mean(lnY)^2 ##ver eq (1) pag 115. Alternativamente poderia ter calculado (Yi-Ymedio)^2
STQ
#STQReg precisa da matrix dos betas e dos valores de X1,X2,
alpha<-matrix(c(1,1,1,1)) #criando matriz de valores 1 para alpha
X<-cbind(alpha,lnX1,lnX2) #cbind consolida as matrizes alpha, X1, e X2 em uma unica matriz 4X3
X
B<-matrix(c(coefficients(regII))) #criando matriz de coeficientes, poderia alternativamente usar os valores dos coeficientes
B
SQReg<-t(B)%*%t(X)%*%lnY-(n%*%mean(lnY)^2) # parcela da variância explicada pela regressão
SQReg
#para SQres podemos usar a matrix dos erros (soma quadrada dos erros da regressão)
E<-matrix(c(residuals(regII))) # criando matrix dos erros
E
SQRes<-t(E)%*%E # parcela da variancia explicada pelos resídos
SQRes
#tabela ANOVA e interpre o teste F
#note que a tabela da pg 117 pode ser replicada com os resultados que ja temos.
#o R, no entanto tem um comando para computar estatísticas da ANOVA.
anova<-anova(regII) # comparando os dois modelos na tabela ANOVA
anova #
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # 147.31
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regII)
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # 147.31
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regII) #a probabilidade de incorrer em erro ao rejeitar H0=B1=B2=0 é de 5.8%, logo se pode rejeitar H0.
#c)construa a tabela ANOVA e interpre o teste F
#note que a tabela da pg 117 pode ser replicada com os resultados que ja temos.
#o R, no entanto tem um comando para computar estatísticas da ANOVA.
anova<-anova(regI) # comparando os dois modelos na tabela ANOVA
anova #
# a estatística F representa a relaçao entre SQReg e SQRes, ponderados pelos respectivos graus de liberdade
F_stat<-(SQReg/k)/(SQRes/(n-k-1))
F_stat # 8.25
#À medida que o modelo contribua significativamente para explicar o comportamento de Y, a SQReg tende a ser máxima e a SQRes mínima., fazendo que
#a estatística F apresente valores elevados ( mínimo =1). Assim, quanto maior a estatistica F, mais evidências teremos para rejeitar H0 = B1=B2=0.
#Olhar a saída de regI nos ajuda a interpretar o F
summary(regI) #a probabilidade de incorrer em erro ao rejeitar H0=B1=B2=0 é de 23.9%, logo não se pode rejeitar H0.
#limpar memória
rm(list=ls(all=TRUE))
# direcionar o R para buscar e escrever no meu diretorio de trabalho
setwd("/Volumes/Seagate Expansion Drive/Banco de Dados /Freensna")
# listar os arquivos do diretorio de trabalho
dir()
# direcionar o R para buscar e escrever no meu diretorio de trabalho
setwd("/Volumes/Seagate Expansion Drive/Banco de Dados /Freensna")
#limpar memória
rm(list=ls(all=TRUE))
# direcionar o R para buscar e escrever no meu diretorio de trabalho
setwd("/Volumes/Seagate Expansion Drive/Banco de Dados /Freensna")
#limpar memória
rm(list=ls(all=TRUE))
# direcionar o R para buscar e escrever no meu diretorio de trabalho
setwd("/Volumes/Seagate Expansion Drive/Banco de Dados /Freensna")
# direcionar o R para buscar e escrever no meu diretorio de trabalho
setwd("/Volumes/Seagate Expansion Drive/Banco de Dados /Freensna")
set("/Users/pauloricardo/Desktop")
setwd("/Users/pauloricardo/Desktop")
dir()
library(foreign)
d1<- read.dta("ES-Indicators-Database-Global-Methodology.dta")
head(10)
head(d1)
# Uma pesquisa com o preço da cesta básica na RMC, retornou uma
# série de dados com preços de diferentes estabelecimentos.
# Verificou-se que os preços são normalmente distribuídos,
# com média de  R$153,00 e desvio padrão R$3,00.
# Qual a probabilidade de um consumidor comprar uma cesta por R$160,00 ou mais ?
# Declarar média, x e desvio padrão;
q <- 160
mu <- 153
sigma <- 3
# Usar a formula para áreas na probabilidade normal;
# p ( probabilidade)
# q ( número/quantidade dentro da distribuição)
# norm ( normal);  t student (t); F (F); uniforme (unif)
pnorm(q,mu,sigma,lower.tail = FALSE)
# A probabilidade de encontrar uma cesta com preço de R$160,00
# ou mais é de aproximadamente 1%.
# Distribuição Normal
mu <- 77
sigma <- 20
# a (q)uantidade de horas que corta a distribuição em 0.20 na cauda da direita.
qnorm(0.20,mu,sigma,lower.tail = FALSE)
pnorm(40,30,8.20, lower.tail = FALSE)
pnorm(20,30,8.20,lower.tail = TRUE)
qnorm(0.10,30,8.20,lower.tail = FALSE)
pnorm(50,77,20,lower.tail = TRUE)
pnorm(100,77,20,lower.tail = TRUE)
77-50
100-77
pnorm(100,77,20,lower.tail = FALSE)
qnorm(0.20,77,20,lower.tail = FALSE)
pnorm(50,77,20,lower.tail = TRUE)
curve(dchisq(x, df = 10), from = 0, to = 40)
# Abrir o banco food do PoEdata
data(food, package = "PoEdata")
summary(food)
# Rodar um modelo para calcular a elasticidade-gasto da renda
mod_alimen <- lm(log(food_exp) ~ log(income), food)
summary(mod_alimen)
# Rodar um modelo para calcular a elasticidade-gasto da renda
mod_alimen <- lm(log(food_exp) ~ log(income), food)
summary(mod_alimen)
# Iniciar um diagnóstico gráfico
plot(mod1)
# Iniciar um diagnóstico gráfico
plot(mod_alimen)
# Iniciar um diagnóstico gráfico
plot(log(food_exp) ~ log(income), food)
# Iniciar um diagnóstico gráfico
plot(log(food_exp) ~ log(income), food)
# Iniciar um diagnóstico gráfico
plot(log(food_exp) ~ log(income), food,
main = "Diagrama de Dispersão Renda Vs Gasto com Alimentação",
xlab="Logarítmo da Renda",
ylab="Logarítmo do Gasto com Alimentação",
col="red")
abline(mod_alimen)
# Modelo de Regressão Múltipla.
data(cps,package = "PoEdata")
head(cps)
mod_wage <- lm(wage ~ educ + age, cps)
summary(mod_wage)
plot(wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Salário Vs Salário Previsto",
xlab="Valores previstos do salário",
ylab="Salário",
col="red")
abline(mod_wage)
plot(wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Salário Vs Salário Previsto",
xlab="Valores previstos do salário",
ylab="Salário",
col="red")
# outro diagnóstico gráfico envolve olhar diretamente os resíduos
res_mod_alimen <- resid(mod_alimen)
food_exp_hat <- predict(mod_alimen)
plot(res_mod_alimen ~ food_exp_hat, food,
main = "Diagrama de Dispersão Resíduos Vs Gasto Previsto",
xlab="Valores previstos do gasto",
ylab="Resíduos",
col="red")
abline(h=0)
plot(res_mod_wage ~ predict(mod_wage), wage,
main = "Diagrama de Dispersão Resíduos Vs Salário Previsto",
xlab="Valores previstos do Salário",
ylab="Resíduos",
col="red")
plot(res_mod_wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Resíduos Vs Salário Previsto",
xlab="Valores previstos do Salário",
ylab="Resíduos",
col="red")
res_mod_wage <- resid(mod_wage)
plot(res_mod_wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Resíduos Vs Salário Previsto",
xlab="Valores previstos do Salário",
ylab="Resíduos",
col="red")
abline(h=0)
library(lmtest)
bptest(mod_alimen)
bptest(mod_wage)
# abrir o banco food do PoEdata
data(food, package = "PoEdata")
summary(food)
# Rodar um modelo para estimar a elasticidade renda dos gastos com
# alimentação
mod_alimen <- lm(log(food_exp) ~ log(income), food)
summary(mod_alimen)
exp(3.96)
# Rodar o modelo para determinação dos salários a partir da escolaridade
# e da idade
data(cps, package = "PoEdata")
head(cps)
mod_wage <- lm(wage ~ educ + age, cps)
summary(mod_wage)
# Modelo de regressão simples
plot(log(food_exp) ~ log(income), food,
main = "Diagrama de Dispersão Renda Vs Gasto com Alimentação",
xlab = "Logarítmo da Renda",
ylab = "Logarítmo do Gasto",
col = "red")
abline(mod_alimen)
# Modelo de regressão múltipla
plot(wage ~ predicted(wage), cps,
main = "Diagrama de Dispersão Salário Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Salários",
col = "red")
# Modelo de regressão múltipla
plot(wage ~ predicte(wage), cps,
main = "Diagrama de Dispersão Salário Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Salários",
col = "red")
# Modelo de regressão múltipla
plot(wage ~ predict(wage), cps,
main = "Diagrama de Dispersão Salário Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Salários",
col = "red")
# Modelo de regressão múltipla
plot(wage ~ predict(wage), cps,
main = "Diagrama de Dispersão Salário Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Salários",
col = "red")
# Modelo de regressão múltipla
plot(wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Salário Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Salários",
col = "red")
summary(mod_wage)
res_mod_wage <- resid(mod_wage)
plot(res_mod_wage ~ predict(mod_wage), cps,
main = "Diagrama de Dispersão Resíduos Vs Salários Previstos",
xlab = "Salários Previstos (educ+age)",
ylab = "Resíduos",
col = "red")
abline(h=0)
# LIbraries
library(tidyverse)
library(curl)
# EXP : loading old-version and removing 2022 data
load(url("https://github.com/Observatorio-PUC-Campinas/Informativos-e-Estudos-Tematicos/blob/main/banco%20de%20dados/EXP_MUN_COMPLETA_SP.RData?raw=true"))
exp_up<-  filter(exp_up,CO_ANO<2022)
# EXP : read 2022 data and bind to old-version
exp_up <-read.csv2("https://balanca.economia.gov.br/balanca/bd/comexstat-bd/mun/EXP_2022_MUN.csv",
stringsAsFactors = F)  %>%
filter(SG_UF_MUN=="SP") %>%
mutate(VL_FOB=as.numeric(VL_FOB)) %>%
mutate(SH4=as.factor(SH4)) %>%
mutate(SH4=str_sub(paste0(0,SH4),-4)) %>%
mutate(CO_PORTO=NULL) %>%
rename(VL_FOB_EXP=VL_FOB)%>%
bind_rows(exp_up)
imp_up<-  filter(imp_up,CO_ANO<2022)
# IMP : loading old-version and removing 2022 data
load(url("https://github.com/Observatorio-PUC-Campinas/Informativos-e-Estudos-Tematicos/blob/main/banco%20de%20dados/IMP_MUN_COMPLETA_SP.RData?raw=true"))
imp_up<-  filter(imp_up,CO_ANO<2022)
# IMP : read 2022 data and bind to old-version
imp_up <-read.csv2("https://balanca.economia.gov.br/balanca/bd/comexstat-bd/mun/IMP_2022_MUN.csv",
stringsAsFactors = F) %>%
filter(SG_UF_MUN=="SP") %>%
mutate(VL_FOB=as.numeric(VL_FOB)) %>%
mutate(SH4=as.factor(SH4)) %>%
mutate(SH4=str_sub(paste0(0,SH4),-4)) %>%
mutate(CO_PORTO=NULL) %>%
rename(VL_FOB_IMP=VL_FOB)%>%
bind_rows(imp_up)
# EXP : loading old-version and removing 2022 data
load(url("https://github.com/Observatorio-PUC-Campinas/Informativos-e-Estudos-Tematicos/blob/main/banco%20de%20dados/EXP_MUN_COMPLETA_SP.RData?raw=true"))
str(exp_up)
str(imp_up)
imp_up<-  imp_up %>%
filter(CO_ANO<2022) %>%
mutate(SH4=as.factor(SH4)) %>%
mutate(SH4=str_sub(paste0(0,SH4),-4))
# IMP : read 2022 data and bind to old-version
imp_up <-read.csv2("https://balanca.economia.gov.br/balanca/bd/comexstat-bd/mun/IMP_2022_MUN.csv",
stringsAsFactors = F) %>%
filter(SG_UF_MUN=="SP") %>%
mutate(VL_FOB=as.numeric(VL_FOB)) %>%
mutate(SH4=as.factor(SH4)) %>%
mutate(SH4=str_sub(paste0(0,SH4),-4)) %>%
mutate(CO_PORTO=NULL) %>%
rename(VL_FOB_IMP=VL_FOB)%>%
bind_rows(imp_up)
View(imp_up)
# IMP : loading old-version and removing 2022 data
load(url("https://github.com/Observatorio-PUC-Campinas/Informativos-e-Estudos-Tematicos/blob/main/banco%20de%20dados/IMP_MUN_COMPLETA_SP.RData?raw=true"))
View(imp_up)
pivots(113060,113880,114010,112545)
# pivot funtion
pivots<-function(c,o,h,l){
pp<-(h+l+c)/3
r1<- (pp*2)-l
r2<-pp + (h-l)
r3<-pp+ 2*(h-l)
s1<-(pp *2)-h
s2<-pp-(h-l)
s3<-pp- 2*(h-l)
pivots<-data.frame(r3,r2,r1,pp,s1,s2,s3)
return(pivots)
}
pivots(113060,113880,114010,112545)
132.87/2
CO_UF_MUN <- read.csv("https://github.com/PedroTL/Projects/blob/main/Banco%20de%20Dados/CO_UF_MUN.csv")
CO_UF_MUN <- read.csv2("https://github.com/PedroTL/Projects/blob/main/Banco%20de%20Dados/CO_UF_MUN.csv")
CO_UF_MUN <- read.csv2("https://github.com/PedroTL/Projects/blob/main/Banco%20de%20Dados/CO_UF_MUN.csv")
CO_UF_MUN <- read.csv("https://github.com/PedroTL/Projects/blob/main/Banco%20de%20Dados/CO_UF_MUN.csv")
View(CO_UF_MUN)
CO_UF_MUN <- read.csv("https://raw.githubusercontent.com/PedroTL/Projects/main/Banco%20de%20Dados/CO_UF_MUN.csv")
View(CO_UF_MUN)
setwd("/Volumes/Paulo_HD/github-informativos/Bancos-de-dados")
write.csv(CO_UF_MUN,"CO_UF_MUN.csv", row.names = F)
co_pais_mdic_ <- read.csv2("https://raw.githubusercontent.com/PedroTL/Projects/main/Banco%20de%20Dados/co_pais_mdic_.csv")
View(co_pais_mdic_)
write.csv(co_pais_mdic_,"co_pais_mdic_.csv", row.names = F)
t <- read.csv("co_pais_mdic_.csv")
View(t)
pci_hs07_rankings <- read.csv("https://github.com/PedroTL/Projects/blob/main/Banco%20de%20Dados/pci_hs07_rankings.csv?raw=true")
View(pci_hs07_rankings)
write.csv(pci_hs07_rankings,"pci_hs07_rankings.csv", row.names = F)
x<- "abc"
y<- "def"
x+y
x <- c(a,b,c,d)
x <- c("a","b","c","d")
x[0]
x[1]
x[1] = "j"
